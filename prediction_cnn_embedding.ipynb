{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import (\n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score, \n",
    "    classification_report,\n",
    "    accuracy_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras.initializers import Constant\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', low_memory=False)\n",
    "train_id = pd.read_csv('train.csv', low_memory=False, usecols = ['id'])\n",
    "test_id  = pd.read_csv('test.csv', low_memory=False, usecols = ['id'])\n",
    "train_target = pd.read_csv('train.csv', usecols = ['target'])\n",
    "embedding_matrix = pd.read_csv('data_process/embedding_matrix100d').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "totaldata = pd.read_csv('data_process/totaldata.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10876, 56)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totaldata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del totaldata['text']\n",
    "del totaldata['keyword']\n",
    "del totaldata['location']\n",
    "del totaldata['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = totaldata[totaldata['target'] != 2]\n",
    "test = totaldata[totaldata['target'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train['target']\n",
    "del test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_num = train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = embedding_matrix.shape[0]\n",
    "e_num = embedding_matrix.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().any().any(), train.isna().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['target', 'keyword_metric', 'domain_metric_mean', 'domain_metric_std',\n",
       "       'domain_metric_max', 'domain_metric_min', 'textsize',\n",
       "       'punctuation_count', 'word_mean_len', 'haslocacion', 'word_count',\n",
       "       'upper_count', 'white_count', 'url_count', 'hashtag_count',\n",
       "       'mention_count', 'PRP$', 'NNS', 'VBP', 'DT', 'NNP', 'IN', 'NN', 'PRP',\n",
       "       'VBD', 'TO', 'VB', 'VBG', 'VBN', 'JJ', 'CC', 'RB', 'VBZ', 'MD', 'EX',\n",
       "       'CD', 'WP', 'RP', 'NNPS', 'JJR', 'WRB', 'JJS', 'WDT', 'RBR', 'RBS',\n",
       "       'FW', 'PDT', 'POS', 'UH', 'SYM', 'WP$', ''''],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totaldata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"data_process/tweet_pad100d.pickle\",\"rb\")\n",
    "tweet_pad = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedd_train =tweet_pad[:train.shape[0]]\n",
    "embedd_test=tweet_pad[train.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7613, 100), (3263, 100), (7613, 51), (3263, 51))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedd_train.shape, embedd_test.shape, train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedd_test = pd.DataFrame(embedd_test)\n",
    "embedd_train = pd.DataFrame(embedd_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.reset_index(inplace=True)\n",
    "test = test.drop('index',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = MinMaxScaler()\n",
    "train = pd.DataFrame(scaled.fit_transform(train), columns= train.columns)\n",
    "test = pd.DataFrame(scaled.fit_transform(test), columns= test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['keyword_metric', 'domain_metric_mean', 'domain_metric_std',\n",
       "       'domain_metric_max', 'domain_metric_min', 'textsize',\n",
       "       'punctuation_count', 'word_mean_len', 'haslocacion', 'word_count',\n",
       "       'upper_count', 'white_count', 'url_count', 'hashtag_count',\n",
       "       'mention_count', 'PRP$', 'NNS', 'VBP', 'DT', 'NNP', 'IN', 'NN', 'PRP',\n",
       "       'VBD', 'TO', 'VB', 'VBG', 'VBN', 'JJ', 'CC', 'RB', 'VBZ', 'MD', 'EX',\n",
       "       'CD', 'WP', 'RP', 'NNPS', 'JJR', 'WRB', 'JJS', 'WDT', 'RBR', 'RBS',\n",
       "       'FW', 'PDT', 'POS', 'UH', 'SYM', 'WP$', ''''],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.concat([test,embedd_test],axis=1)\n",
    "train = pd.concat([train,embedd_train],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().any().any() , test.isna().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_input = layers.Input(shape=(f_num,), name=\"features\")\n",
    "x = layers.Dense(512, activation='relu')(features_input)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "features_output = layers.Dropout(0.2)(x)\n",
    "\n",
    "emb_input = layers.Input(shape=(None,), name=\"embedd\")\n",
    "x = layers.Embedding(num_words,e_num,\n",
    "                     embeddings_initializer=Constant(embedding_matrix),\n",
    "                     input_length=e_num,trainable=False)(emb_input)\n",
    "x = layers.SpatialDropout1D(0.08)(x)\n",
    "x = layers.Conv1D(512, 7, padding=\"valid\", activation='relu', strides=4)(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "emb_output = layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "#x = layers.GRU(128,dropout=0.1,recurrent_dropout=0.08,return_sequences=True)(x)\n",
    "\n",
    "x = layers.concatenate([features_output, emb_output])\n",
    "x = layers.Dense(256,activation='relu')(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(32,activation='relu')(x)\n",
    "x = layers.Dropout(0.12)(x)\n",
    "x = layers.Dense(6,activation='relu')(x)\n",
    "x = layers.Dropout(0.14)(x)\n",
    "conv1d = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model4 = Model(\n",
    "    inputs=[features_input,emb_input],\n",
    "    outputs=[conv1d],\n",
    ")\n",
    "#optimzer = SGD(learning_rate=1e-5, momentum=0.8)\n",
    "optimzer=Adam(learning_rate=1e-5)\n",
    "model4.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=optimzer,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_input = layers.Input(shape=(f_num,), name=\"features\")\n",
    "x = layers.Dense(256, activation='relu')(features_input)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "features_output = layers.Dropout(0.2)(x)\n",
    "\n",
    "emb_input = layers.Input(shape=(None,), name=\"embedd\")\n",
    "x = layers.Embedding(input_dim=embedding_matrix.shape[0], \n",
    "                        output_dim=embedding_matrix.shape[1], \n",
    "                        weights = [embedding_matrix], \n",
    "                        input_length=e_num)(emb_input)\n",
    "x = layers.Bidirectional(layers.LSTM(100, return_sequences = True, recurrent_dropout=0.2, kernel_regularizer=regularizers.l2(0.01)))(x)\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "emb_output = layers.Dropout(0.3)(x)\n",
    "\n",
    "#x = layers.GRU(128,dropout=0.1,recurrent_dropout=0.08,return_sequences=True)(x)\n",
    "\n",
    "x = layers.concatenate([features_output, emb_output])\n",
    "x = layers.Dense(128,activation='relu')(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(24,activation='relu')(x)\n",
    "x = layers.Dropout(0.12)(x)\n",
    "x = layers.Dense(6,activation='relu')(x)\n",
    "x = layers.Dropout(0.14)(x)\n",
    "conv1d = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model4 = Model(\n",
    "    inputs=[features_input,emb_input],\n",
    "    outputs=[conv1d],\n",
    ")\n",
    "#optimzer = SGD(learning_rate=1e-5, momentum=0.8)\n",
    "optimzer=Adam(learning_rate=1e-5)\n",
    "model4.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=optimzer,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#early_stop = EarlyStopping(\n",
    "#    monitor='val_accuracy',\n",
    "#    patience=6)\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'model.h5', \n",
    "    monitor = 'val_loss', \n",
    "    verbose = 1, \n",
    "    save_best_only = True\n",
    ")\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor = 'val_loss', \n",
    "    factor = 0.2, \n",
    "    verbose = 1, \n",
    "    patience = 5,                        \n",
    "    min_lr = 0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "609/609 [==============================] - ETA: 0s - loss: 0.9603 - accuracy: 0.8131\n",
      "Epoch 00001: val_loss improved from 0.93882 to 0.92497, saving model to model.h5\n",
      "609/609 [==============================] - 87s 142ms/step - loss: 0.9603 - accuracy: 0.8131 - val_loss: 0.9250 - val_accuracy: 0.8313\n",
      "Epoch 2/100\n",
      "609/609 [==============================] - ETA: 0s - loss: 0.9342 - accuracy: 0.8284\n",
      "Epoch 00002: val_loss improved from 0.92497 to 0.91231, saving model to model.h5\n",
      "609/609 [==============================] - 86s 141ms/step - loss: 0.9342 - accuracy: 0.8284 - val_loss: 0.9123 - val_accuracy: 0.8332\n",
      "Epoch 3/100\n",
      "609/609 [==============================] - ETA: 0s - loss: 0.9311 - accuracy: 0.8176\n",
      "Epoch 00003: val_loss improved from 0.91231 to 0.90090, saving model to model.h5\n",
      "609/609 [==============================] - 90s 148ms/step - loss: 0.9311 - accuracy: 0.8176 - val_loss: 0.9009 - val_accuracy: 0.8326\n",
      "Epoch 4/100\n",
      "609/609 [==============================] - ETA: 0s - loss: 0.9192 - accuracy: 0.8159\n",
      "Epoch 00004: val_loss improved from 0.90090 to 0.89022, saving model to model.h5\n",
      "609/609 [==============================] - 82s 134ms/step - loss: 0.9192 - accuracy: 0.8159 - val_loss: 0.8902 - val_accuracy: 0.8299\n",
      "Epoch 5/100\n",
      "609/609 [==============================] - ETA: 0s - loss: 0.9131 - accuracy: 0.8182\n",
      "Epoch 00005: val_loss improved from 0.89022 to 0.87951, saving model to model.h5\n",
      "609/609 [==============================] - 82s 134ms/step - loss: 0.9131 - accuracy: 0.8182 - val_loss: 0.8795 - val_accuracy: 0.8339\n",
      "Epoch 6/100\n",
      "609/609 [==============================] - ETA: 0s - loss: 0.9005 - accuracy: 0.8143\n",
      "Epoch 00006: val_loss improved from 0.87951 to 0.86944, saving model to model.h5\n",
      "609/609 [==============================] - 87s 143ms/step - loss: 0.9005 - accuracy: 0.8143 - val_loss: 0.8694 - val_accuracy: 0.8332\n",
      "Epoch 7/100\n",
      "609/609 [==============================] - ETA: 0s - loss: 0.8889 - accuracy: 0.8210\n",
      "Epoch 00007: val_loss improved from 0.86944 to 0.85965, saving model to model.h5\n",
      "609/609 [==============================] - 97s 159ms/step - loss: 0.8889 - accuracy: 0.8210 - val_loss: 0.8596 - val_accuracy: 0.8332\n",
      "Epoch 8/100\n",
      "609/609 [==============================] - ETA: 0s - loss: 0.8719 - accuracy: 0.8292\n",
      "Epoch 00008: val_loss improved from 0.85965 to 0.85051, saving model to model.h5\n",
      "609/609 [==============================] - 92s 152ms/step - loss: 0.8719 - accuracy: 0.8292 - val_loss: 0.8505 - val_accuracy: 0.8326\n",
      "Epoch 9/100\n",
      "609/609 [==============================] - ETA: 0s - loss: 0.8614 - accuracy: 0.8245\n",
      "Epoch 00009: val_loss improved from 0.85051 to 0.84271, saving model to model.h5\n",
      "609/609 [==============================] - 88s 145ms/step - loss: 0.8614 - accuracy: 0.8245 - val_loss: 0.8427 - val_accuracy: 0.8332\n",
      "Epoch 10/100\n",
      "609/609 [==============================] - ETA: 0s - loss: 0.8545 - accuracy: 0.8194\n",
      "Epoch 00010: val_loss improved from 0.84271 to 0.83421, saving model to model.h5\n",
      "609/609 [==============================] - 88s 144ms/step - loss: 0.8545 - accuracy: 0.8194 - val_loss: 0.8342 - val_accuracy: 0.8306\n",
      "Epoch 11/100\n",
      "609/609 [==============================] - ETA: 0s - loss: 0.8458 - accuracy: 0.8240\n",
      "Epoch 00011: val_loss improved from 0.83421 to 0.82635, saving model to model.h5\n",
      "609/609 [==============================] - 88s 145ms/step - loss: 0.8458 - accuracy: 0.8240 - val_loss: 0.8264 - val_accuracy: 0.8313\n",
      "Epoch 12/100\n",
      "609/609 [==============================] - ETA: 0s - loss: 0.8305 - accuracy: 0.8248\n",
      "Epoch 00012: val_loss improved from 0.82635 to 0.81931, saving model to model.h5\n",
      "609/609 [==============================] - 87s 143ms/step - loss: 0.8305 - accuracy: 0.8248 - val_loss: 0.8193 - val_accuracy: 0.8339\n",
      "Epoch 13/100\n",
      "609/609 [==============================] - ETA: 0s - loss: 0.8236 - accuracy: 0.8319\n",
      "Epoch 00013: val_loss improved from 0.81931 to 0.81252, saving model to model.h5\n",
      "609/609 [==============================] - 88s 144ms/step - loss: 0.8236 - accuracy: 0.8319 - val_loss: 0.8125 - val_accuracy: 0.8332\n",
      "Epoch 14/100\n",
      " 81/609 [==>...........................] - ETA: 1:23 - loss: 0.8274 - accuracy: 0.8136"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-3e6a031d28ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m    \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history=model4.fit(\n",
    "    {\"features\": train.values[:,:f_num], \"embedd\": train.values[:,f_num:]},\n",
    "    train_target.values,\n",
    "    batch_size=10,\n",
    "    epochs=100,\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    "   callbacks=[reduce_lr,checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy over time')\n",
    "    plt.plot(hist['epoch'], hist['accuracy'],\n",
    "           label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_accuracy'],\n",
    "           label = 'Val Error')\n",
    "    plt.ylim([0,1])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 100)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.values[:,f_num:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>639</td>\n",
       "      <td>1367</td>\n",
       "      <td>53</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>278</td>\n",
       "      <td>154</td>\n",
       "      <td>1223</td>\n",
       "      <td>1729</td>\n",
       "      <td>541</td>\n",
       "      <td>1340</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>708</td>\n",
       "      <td>2645</td>\n",
       "      <td>16341</td>\n",
       "      <td>4557</td>\n",
       "      <td>769</td>\n",
       "      <td>560</td>\n",
       "      <td>253</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>271</td>\n",
       "      <td>3251</td>\n",
       "      <td>5619</td>\n",
       "      <td>1241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121</td>\n",
       "      <td>597</td>\n",
       "      <td>261</td>\n",
       "      <td>227</td>\n",
       "      <td>1165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>154</td>\n",
       "      <td>752</td>\n",
       "      <td>1959</td>\n",
       "      <td>2361</td>\n",
       "      <td>752</td>\n",
       "      <td>19917</td>\n",
       "      <td>19918</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>16</td>\n",
       "      <td>5912</td>\n",
       "      <td>1108</td>\n",
       "      <td>58</td>\n",
       "      <td>178</td>\n",
       "      <td>89</td>\n",
       "      <td>772</td>\n",
       "      <td>4559</td>\n",
       "      <td>185</td>\n",
       "      <td>3232</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>667</td>\n",
       "      <td>443</td>\n",
       "      <td>341</td>\n",
       "      <td>721</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>4156</td>\n",
       "      <td>517</td>\n",
       "      <td>323</td>\n",
       "      <td>81</td>\n",
       "      <td>1663</td>\n",
       "      <td>1796</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>89</td>\n",
       "      <td>177</td>\n",
       "      <td>2589</td>\n",
       "      <td>1443</td>\n",
       "      <td>11</td>\n",
       "      <td>162</td>\n",
       "      <td>177</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2     3      4      5      6     7    8     9   ...  90  \\\n",
       "0      639  1367    53    27      0      0      0     0    0     0  ...   0   \n",
       "1      278   154  1223  1729    541   1340    150     0    0     0  ...   0   \n",
       "2       83     2   708  2645  16341   4557    769   560  253     0  ...   0   \n",
       "3      271  3251  5619  1241      0      0      0     0    0     0  ...   0   \n",
       "4      121   597   261   227   1165      0      0     0    0     0  ...   0   \n",
       "...    ...   ...   ...   ...    ...    ...    ...   ...  ...   ...  ...  ..   \n",
       "3258   154   752  1959  2361    752  19917  19918     0    0     0  ...   0   \n",
       "3259    16  5912  1108    58    178     89    772  4559  185  3232  ...   0   \n",
       "3260   667   443   341   721      0      0      0     0    0     0  ...   0   \n",
       "3261  4156   517   323    81   1663   1796      0     0    0     0  ...   0   \n",
       "3262    89   177  2589  1443     11    162    177    16    0     0  ...   0   \n",
       "\n",
       "      91  92  93  94  95  96  97  98  99  \n",
       "0      0   0   0   0   0   0   0   0   0  \n",
       "1      0   0   0   0   0   0   0   0   0  \n",
       "2      0   0   0   0   0   0   0   0   0  \n",
       "3      0   0   0   0   0   0   0   0   0  \n",
       "4      0   0   0   0   0   0   0   0   0  \n",
       "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  \n",
       "3258   0   0   0   0   0   0   0   0   0  \n",
       "3259   0   0   0   0   0   0   0   0   0  \n",
       "3260   0   0   0   0   0   0   0   0   0  \n",
       "3261   0   0   0   0   0   0   0   0   0  \n",
       "3262   0   0   0   0   0   0   0   0   0  \n",
       "\n",
       "[3263 rows x 100 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedd_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model4.predict([test.values[:,:f_num],embedd_test.values])\n",
    "predict=np.round(predict).astype(int).reshape(3263)\n",
    "submit = pd.read_csv('test.csv', usecols= ['id'])\n",
    "submit['target'] = predict\n",
    "submit.to_csv('submits/submit9.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2126\n",
       "1    1137\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
